{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7a520c2-cf19-4b4d-98b6-bb0fd0e6f6c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mVAEEncoder\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, latent_dim):\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28msuper\u001b[39m(VAEEncoder, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class VAEEncoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(VAEEncoder, self).__init__()\n",
    "        \n",
    "        # Initial convolution\n",
    "        self.conv_initial = nn.Conv2d(3, 64, 3, stride=1, padding=1)\n",
    "        \n",
    "        # Downsampling blocks\n",
    "        self.conv1 = nn.Conv2d(64, 128, 4, stride=2, padding=1)    # 64x64 -> 32x32\n",
    "        self.conv2 = nn.Conv2d(128, 256, 4, stride=2, padding=1)   # 32x32 -> 16x16\n",
    "        self.conv3 = nn.Conv2d(256, 512, 4, stride=2, padding=1)   # 16x16 -> 8x8 (skip connection point)\n",
    "        self.conv4 = nn.Conv2d(512, 1024, 4, stride=2, padding=1)  # 8x8 -> 4x4\n",
    "        \n",
    "        # Batch normalization\n",
    "        self.bn1 = nn.BatchNorm2d(128)\n",
    "        self.bn2 = nn.BatchNorm2d(256)\n",
    "        self.bn3 = nn.BatchNorm2d(512)\n",
    "        self.bn4 = nn.BatchNorm2d(1024)\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.fc_mu = nn.Linear(1024 * 4 * 4, latent_dim)\n",
    "        self.fc_var = nn.Linear(1024 * 4 * 4, latent_dim)\n",
    "        \n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Initial convolution\n",
    "        x = F.leaky_relu(self.conv_initial(x), 0.2)\n",
    "        \n",
    "        # Downsampling path\n",
    "        x = F.leaky_relu(self.bn1(self.conv1(x)), 0.2)\n",
    "        x = F.leaky_relu(self.bn2(self.conv2(x)), 0.2)\n",
    "        \n",
    "        # Save the feature map for the skip connection\n",
    "        skip_connection = F.leaky_relu(self.bn3(self.conv3(x)), 0.2)\n",
    "        \n",
    "        x = F.leaky_relu(self.bn4(self.conv4(skip_connection)), 0.2)\n",
    "        \n",
    "        # Flatten and apply dropout\n",
    "        x = self.dropout(x.view(x.size(0), -1))\n",
    "        \n",
    "        # Generate latent parameters\n",
    "        mu = self.fc_mu(x)\n",
    "        log_var = self.fc_var(x)\n",
    "        \n",
    "        return mu, log_var, skip_connection\n",
    "\n",
    "\n",
    "class VAEDecoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(VAEDecoder, self).__init__()\n",
    "        \n",
    "        # Initial fully connected layer\n",
    "        self.fc = nn.Linear(latent_dim, 1024 * 4 * 4)\n",
    "        \n",
    "        # Upsampling blocks\n",
    "        self.conv1 = nn.ConvTranspose2d(1024, 512, 4, stride=2, padding=1)  # 4x4 -> 8x8\n",
    "        self.conv2 = nn.ConvTranspose2d(1024, 256, 4, stride=2, padding=1)   # 8x8 -> 16x16 (includes skip)\n",
    "        self.conv3 = nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1)   # 16x16 -> 32x32\n",
    "        self.conv4 = nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1)    # 32x32 -> 64x64\n",
    "        \n",
    "        # Batch normalization\n",
    "        self.bn1 = nn.BatchNorm2d(512)\n",
    "        self.bn2 = nn.BatchNorm2d(256)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        # Final convolution for output\n",
    "        self.conv_final = nn.Conv2d(64, 3, 3, stride=1, padding=1)\n",
    "        \n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, z, skip_connection):\n",
    "        # Reshape from latent space\n",
    "        x = F.relu(self.fc(z))\n",
    "        x = x.view(x.size(0), 1024, 4, 4)\n",
    "        \n",
    "        # Upsampling path\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        \n",
    "        # Apply skip connection\n",
    "        # x = torch.cat([x, skip_connection], dim=1)  # Concatenate along channel dimension\n",
    "        # Apply skip connection if provided\n",
    "        if skip_connection is not None:\n",
    "            x = torch.cat([x, skip_connection], dim=1)  # Concatenate along channel dimension\n",
    "        \n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        \n",
    "        # Final convolution with tanh activation\n",
    "        x = torch.tanh(self.conv_final(x))\n",
    "        \n",
    "        return x\n",
    "\n",
    "class ConvVAE(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(ConvVAE, self).__init__()\n",
    "        self.encoder = VAEEncoder(latent_dim)\n",
    "        self.decoder = VAEDecoder(latent_dim)\n",
    "        \n",
    "    def reparameterize(self, mu, log_var):\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5 * log_var)\n",
    "            eps = torch.randn_like(std)\n",
    "            return mu + eps * std\n",
    "        return mu\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Encoder with skip connection\n",
    "        mu, log_var, skip_connection = self.encoder(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        \n",
    "        # Decoder with skip connection\n",
    "        recon_x = self.decoder(z, skip_connection)\n",
    "        return recon_x, mu, log_var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9d865d5-f752-4240-9df2-43aea13c5e08",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ConvVAE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m latent_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m512\u001b[39m \u001b[38;5;66;03m# define latent dimension\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Load model\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mConvVAE\u001b[49m(latent_dim\u001b[38;5;241m=\u001b[39mlatent_dim)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# model\u001b[39;00m\n\u001b[1;32m     20\u001b[0m model \u001b[38;5;241m=\u001b[39m run_vae_training(\n\u001b[1;32m     21\u001b[0m     model, train_loader, val_loader, device, \n\u001b[1;32m     22\u001b[0m     num_epochs\u001b[38;5;241m=\u001b[39mnum_epochs, learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m     name\u001b[38;5;241m=\u001b[39mname, project\u001b[38;5;241m=\u001b[39mproject\n\u001b[1;32m     26\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ConvVAE' is not defined"
     ]
    }
   ],
   "source": [
    "# Model training parameters\n",
    "learning_rate=0.0001\n",
    "step_size=10\n",
    "gamma=0.5\n",
    "\n",
    "kl_weight=0.01\n",
    "\n",
    "num_epochs=40\n",
    "\n",
    "name=f\"run_kl_wgt_{str(kl_weight)}_ep_{num_epochs}_ld_1024_skip_cn\"\n",
    "project=\"assignment-5\"\n",
    "\n",
    "\n",
    "latent_dim = 512 # define latent dimension\n",
    "\n",
    "# Load model\n",
    "model = ConvVAE(latent_dim=latent_dim).to(device)\n",
    "# model\n",
    "\n",
    "model = run_vae_training(\n",
    "    model, train_loader, val_loader, device, \n",
    "    num_epochs=num_epochs, learning_rate=learning_rate,\n",
    "    step_size=step_size, gamma=gamma,\n",
    "    kl_weight=kl_weight,\n",
    "    name=name, project=project\n",
    ")\n",
    "\n",
    "save_path = os.path.join(saved_model_folder, name)\n",
    "torch.save(model, save_path)\n",
    "print(f\"Model saved at: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24d1069f-7701-4cae-8103-eb2c958b5b82",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m(save_path)\n\u001b[1;32m      2\u001b[0m max_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;241m2000\u001b[39m, \u001b[38;5;28mlen\u001b[39m(val_loader\u001b[38;5;241m.\u001b[39mdataset))\n\u001b[1;32m      3\u001b[0m fid_score \u001b[38;5;241m=\u001b[39m compute_fid_score(model, val_loader, device, max_samples\u001b[38;5;241m=\u001b[39mmax_samples)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_model' is not defined"
     ]
    }
   ],
   "source": [
    "model = load_model(save_path)\n",
    "max_samples = min(2000, len(val_loader.dataset))\n",
    "fid_score = compute_fid_score(model, val_loader, device, max_samples=max_samples)\n",
    "print(f\"FID Score for model {name}: {fid_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "207bd022-6e97-4561-bffb-065ebdc5fc75",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(\u001b[43mval_loader\u001b[49m)\n\u001b[1;32m      2\u001b[0m images, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(data_iter)\n\u001b[1;32m      3\u001b[0m visualize_reconstructions(model, images, device)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_loader' is not defined"
     ]
    }
   ],
   "source": [
    "data_iter = iter(val_loader)\n",
    "images, _ = next(data_iter)\n",
    "visualize_reconstructions(model, images, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e50c32-9bae-47b4-8cd9-4ef795403995",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
