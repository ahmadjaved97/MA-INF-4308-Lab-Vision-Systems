{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1874f96d-eff2-4277-b848-f7dab2872430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision.utils import make_grid, save_image\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "import wandb\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ade88d1b-8473-48f3-a05d-9e00052b189a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device Used: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device Used: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ca26cf6-2296-488e-81ad-bc8c44719562",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_folder = \"./saved_models\"\n",
    "os.makedirs(saved_model_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3d4b6c6-5535-4060-ac1b-5c6d7d971147",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AFHQDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        root_dir: path of the parent directory that contains images.\n",
    "        transforms: augmentations applied to the images (can be none or more).\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.class_mapping = {}\n",
    "        \n",
    "        extensions = (\".jpg\", \".jpeg\", \".png\")\n",
    "        # go through all sub-directories\n",
    "        for label, category in enumerate(sorted(os.listdir(root_dir))):\n",
    "            full_path = os.path.join(root_dir, category)\n",
    "            if os.path.exists(full_path):\n",
    "                self.class_mapping[label] = category\n",
    "                for img_name in os.listdir(full_path):\n",
    "                    if img_name.endswith(extensions):\n",
    "                        self.image_paths.append(os.path.join(full_path, img_name))\n",
    "                        self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e506311b-fcb2-454c-af36-25d0d911ea99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Hyperparameters\n",
    "img_size = 64\n",
    "batch_size = 64\n",
    "\n",
    "# dataset paths\n",
    "train_dir = '/home/user/javeda1/stargan-v2/data/afhq/train'\n",
    "val_dir = '/home/user/javeda1/stargan-v2/data/afhq/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16f3a6f4-b993-490e-bf2a-8b663f1b786e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84869ea7-ad2d-471f-bf4e-f17201063f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 14630\n",
      "Validation dataset size: 1500\n"
     ]
    }
   ],
   "source": [
    "# Load the train and val dataset\n",
    "train_dataset = AFHQDataset(root_dir=train_dir, transform=transform)\n",
    "val_dataset = AFHQDataset(root_dir=val_dir, transform=transform)\n",
    "\n",
    "# DataLoaders for train and val sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "train_size = len(train_loader.dataset)\n",
    "val_size = len(val_loader.dataset)\n",
    "\n",
    "print(f\"Train dataset size: {train_size}\")\n",
    "print(f\"Validation dataset size: {val_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09490bd1-6e79-4a56-98fd-f7465bb34dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the FID computation function\n",
    "def compute_fid_score_gan(generator, data_loader, device, latent_dim=256, max_samples=1000):\n",
    "    \"\"\"\n",
    "    Computes the Fréchet Inception Distance (FID) between real and generated images.\n",
    "    \"\"\"\n",
    "    fid = FrechetInceptionDistance(feature=2048).to(device)\n",
    "    generator.eval()\n",
    "    \n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for real_images, _ in data_loader:\n",
    "            batch_size = real_images.size(0)\n",
    "            real_images = real_images.to(device)\n",
    "            \n",
    "            # Generate fake images\n",
    "            noise = torch.randn(batch_size, latent_dim, device=device)\n",
    "            fake_images = generator(noise)\n",
    "            \n",
    "            # Convert images to uint8 and scale to [0, 255]\n",
    "            real_images = (real_images * 0.5 + 0.5).clamp(0, 1)\n",
    "            fake_images = (fake_images * 0.5 + 0.5).clamp(0, 1)\n",
    "            real_images = (real_images * 255).byte()\n",
    "            fake_images = (fake_images * 255).byte()\n",
    "            \n",
    "            fid.update(real_images, real=True)\n",
    "            fid.update(fake_images, real=False)\n",
    "            \n",
    "            total_samples += batch_size\n",
    "            if total_samples >= max_samples:\n",
    "                break\n",
    "    \n",
    "    return fid.compute().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bd5f3df-f281-46de-bef0-34d17ab1bcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training loop\n",
    "def train_dcgan(generator, discriminator, dataloader, latent_dim, epochs, device, lr_g=0.0002, lr_d=0.0008, beta1=0.5, step_size=10, gamma=0.5,\n",
    "               project=\"DCGAN-AFHQ2\", name=\"run1\"):\n",
    "    # Initialize optimizers\n",
    "    optimizer_g = optim.Adam(generator.parameters(), lr=lr_g, betas=(beta1, 0.999))\n",
    "    optimizer_d = optim.Adam(discriminator.parameters(), lr=lr_d, betas=(beta1, 0.999))\n",
    "\n",
    "    # Learning rate schedulers\n",
    "    scheduler_g = optim.lr_scheduler.StepLR(optimizer_g, step_size=step_size, gamma=gamma)\n",
    "    scheduler_d = optim.lr_scheduler.StepLR(optimizer_d, step_size=step_size, gamma=gamma)\n",
    "\n",
    "    # Loss function\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    # Fixed noise for evaluation\n",
    "    fixed_noise = torch.randn(64, latent_dim, device=device)\n",
    "\n",
    "    # Labels for real and fake data\n",
    "    real_label = 0.9  # Label smoothing for real images\n",
    "    fake_label = 0.0\n",
    "\n",
    "    # Initialize WandB\n",
    "    wandb.init(project=project, name=name,reinit=False, config={\n",
    "        \"latent_dim\": latent_dim,\n",
    "        \"epochs\": epochs,\n",
    "        \"lr_g\": lr_g,\n",
    "        \"lr_d\": lr_d,\n",
    "        \"beta1\": beta1,\n",
    "        \"step_size\": step_size,\n",
    "        \"gamma\": gamma\n",
    "    })\n",
    "\n",
    "    # Output directory for generated images\n",
    "    output_dir = \"generated_images\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        g_loss_total = 0.0\n",
    "        d_loss_total = 0.0\n",
    "\n",
    "        for i, (real_images, _) in enumerate(tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\")):\n",
    "            batch_size = real_images.size(0)\n",
    "\n",
    "            real_images = real_images.to(device)\n",
    "\n",
    "            # Train Discriminator\n",
    "            if i % 3 == 0:  # Train the discriminator less frequently\n",
    "                discriminator.zero_grad()\n",
    "\n",
    "                # Real images\n",
    "                labels_real = torch.full((batch_size,), real_label, device=device)\n",
    "                output_real = discriminator(real_images).view(-1)\n",
    "                loss_real = criterion(output_real, labels_real)\n",
    "\n",
    "                # Fake images\n",
    "                noise = torch.randn(batch_size, latent_dim, device=device)\n",
    "                fake_images = generator(noise)\n",
    "                labels_fake = torch.full((batch_size,), fake_label, device=device)\n",
    "                output_fake = discriminator(fake_images.detach()).view(-1)\n",
    "                loss_fake = criterion(output_fake, labels_fake)\n",
    "\n",
    "                # Combine losses and backpropagate\n",
    "                d_loss = loss_real + loss_fake\n",
    "                d_loss.backward()\n",
    "                optimizer_d.step()\n",
    "\n",
    "                d_loss_total += d_loss.item()\n",
    "\n",
    "            # Train Generator\n",
    "            generator.zero_grad()\n",
    "            noise = torch.randn(batch_size, latent_dim, device=device)\n",
    "            fake_images = generator(noise)\n",
    "            output = discriminator(fake_images).view(-1)\n",
    "            g_loss = criterion(output, labels_real)\n",
    "            g_loss.backward()\n",
    "            optimizer_g.step()\n",
    "\n",
    "            g_loss_total += g_loss.item()\n",
    "\n",
    "        # Step learning rate schedulers\n",
    "        scheduler_g.step()\n",
    "        scheduler_d.step()\n",
    "\n",
    "        # Log learning rates\n",
    "        # wandb.log({\"Learning Rate Generator\": scheduler_g.get_last_lr()[0],\n",
    "        #            \"Learning Rate Discriminator\": scheduler_d.get_last_lr()[0]})\n",
    "\n",
    "        # Log losses and generate sample images\n",
    "        avg_g_loss = g_loss_total / len(dataloader)\n",
    "        avg_d_loss = d_loss_total / len(dataloader)\n",
    "\n",
    "        # Compute FID score\n",
    "        fid_score = compute_fid_score_gan(generator, dataloader, device, latent_dim)\n",
    "\n",
    "        # Log metrics\n",
    "        # wandb.log({\"Generator Loss\": avg_g_loss, \"Discriminator Loss\": avg_d_loss, \"FID Score\": fid_score})\n",
    "\n",
    "        # Log and save generated images as grids\n",
    "        with torch.no_grad():\n",
    "            sample_images = generator(fixed_noise).detach().cpu()\n",
    "            sample_grid = make_grid(sample_images, nrow=8, normalize=True, scale_each=True)\n",
    "\n",
    "            real_images_grid = make_grid(real_images[:64], nrow=8, normalize=True, scale_each=True)\n",
    "\n",
    "            # Save generated grid to disk\n",
    "            save_image(sample_grid, os.path.join(output_dir, f\"epoch_{epoch+1:03d}_generated.png\"))\n",
    "\n",
    "        wandb.log({\n",
    "            \"Generated Images Grid\": wandb.Image(sample_grid, caption=\"Generated Images\"),\n",
    "            \"Real Images Grid\": wandb.Image(real_images_grid, caption=\"Real Images\"),\n",
    "            \"Learning Rate Generator\": scheduler_g.get_last_lr()[0],\n",
    "            \"Learning Rate Discriminator\": scheduler_d.get_last_lr()[0],\n",
    "            \"Generator Loss\": avg_g_loss, \"Discriminator Loss\": avg_d_loss, \"FID Score\": fid_score\n",
    "        })\n",
    "\n",
    "    # Finish the WandB run\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b7a3bf4-51bb-472c-b29e-f6e3d7206768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define weights initialization function\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0b60ca9-226f-4fd4-90e0-73c3e5e6394e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim=256, num_channels=3):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        # Initial dense projection from latent space\n",
    "        self.fc = nn.Linear(latent_dim, 512 * 4 * 4)\n",
    "        self.bn1 = nn.BatchNorm2d(512)\n",
    "        self.relu1 = nn.ReLU(True)\n",
    "        \n",
    "        # Second block: 512 x 4 x 4 -> 256 x 8 x 8\n",
    "        self.upsample2 = nn.Upsample(scale_factor=2)\n",
    "        self.conv2 = nn.Conv2d(512, 256, 3, 1, 1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(256)\n",
    "        self.relu2 = nn.ReLU(True)\n",
    "        \n",
    "        # Third block: 256 x 8 x 8 -> 128 x 16 x 16\n",
    "        self.upsample3 = nn.Upsample(scale_factor=2)\n",
    "        self.conv3 = nn.Conv2d(256, 128, 3, 1, 1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.relu3 = nn.ReLU(True)\n",
    "        \n",
    "        # Fourth block: 128 x 16 x 16 -> 64 x 32 x 32\n",
    "        self.upsample4 = nn.Upsample(scale_factor=2)\n",
    "        self.conv4 = nn.Conv2d(128, 64, 3, 1, 1, bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.relu4 = nn.ReLU(True)\n",
    "        \n",
    "        # Final block: 64 x 32 x 32 -> num_channels x 64 x 64\n",
    "        self.upsample5 = nn.Upsample(scale_factor=2)\n",
    "        self.conv5 = nn.Conv2d(64, num_channels, 3, 1, 1, bias=False)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initial projection and reshape\n",
    "        x = self.fc(x.view(-1, x.size(1)))\n",
    "        x = x.view(-1, 512, 4, 4)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        \n",
    "        # Second block\n",
    "        x = self.upsample2(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        \n",
    "        # Third block\n",
    "        x = self.upsample3(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu3(x)\n",
    "        \n",
    "        # Fourth block\n",
    "        x = self.upsample4(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu4(x)\n",
    "        \n",
    "        # Final block\n",
    "        x = self.upsample5(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.tanh(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, num_channels=3):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        # First convolution block\n",
    "        self.conv1 = nn.Conv2d(num_channels, 64, 4, 2, 1, bias=False)\n",
    "        self.lrelu1 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        \n",
    "        # Second convolution block\n",
    "        self.conv2 = nn.Conv2d(64, 128, 4, 2, 1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.lrelu2 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        \n",
    "        # Third convolution block\n",
    "        self.conv3 = nn.Conv2d(128, 256, 4, 2, 1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.lrelu3 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        \n",
    "        # Fourth convolution block\n",
    "        self.conv4 = nn.Conv2d(256, 512, 4, 2, 1, bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(512)\n",
    "        self.lrelu4 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        \n",
    "        # Final convolution\n",
    "        self.conv5 = nn.Conv2d(512, 1, 4, 1, 0, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.lrelu1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.lrelu2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.lrelu3(x)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.lrelu4(x)\n",
    "        \n",
    "        x = self.conv5(x)\n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        return x.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42753448-c473-44df-b78a-f1e42564ee28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/user/javeda1/MA-INF-4308-Lab-Vision-Systems/Assignment-6/wandb/run-20250119_204106-e95gfff8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ahmadjaved97/DCGAN-AFHQ2/runs/e95gfff8' target=\"_blank\">run2</a></strong> to <a href='https://wandb.ai/ahmadjaved97/DCGAN-AFHQ2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ahmadjaved97/DCGAN-AFHQ2' target=\"_blank\">https://wandb.ai/ahmadjaved97/DCGAN-AFHQ2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ahmadjaved97/DCGAN-AFHQ2/runs/e95gfff8' target=\"_blank\">https://wandb.ai/ahmadjaved97/DCGAN-AFHQ2/runs/e95gfff8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/40: 100%|█████████████████████████████████████████| 229/229 [00:08<00:00, 25.73it/s]\n",
      "Epoch 2/40: 100%|█████████████████████████████████████████| 229/229 [00:09<00:00, 25.15it/s]\n",
      "Epoch 3/40: 100%|█████████████████████████████████████████| 229/229 [00:08<00:00, 25.62it/s]\n",
      "Epoch 4/40: 100%|█████████████████████████████████████████| 229/229 [00:09<00:00, 25.35it/s]\n",
      "Epoch 5/40: 100%|█████████████████████████████████████████| 229/229 [00:09<00:00, 25.25it/s]\n",
      "Epoch 6/40: 100%|█████████████████████████████████████████| 229/229 [00:08<00:00, 26.16it/s]\n",
      "Epoch 7/40: 100%|█████████████████████████████████████████| 229/229 [00:09<00:00, 25.19it/s]\n",
      "Epoch 8/40: 100%|█████████████████████████████████████████| 229/229 [00:09<00:00, 25.33it/s]\n",
      "Epoch 9/40: 100%|█████████████████████████████████████████| 229/229 [00:08<00:00, 25.77it/s]\n",
      "Epoch 10/40: 100%|████████████████████████████████████████| 229/229 [00:08<00:00, 26.59it/s]\n",
      "Epoch 11/40: 100%|████████████████████████████████████████| 229/229 [00:08<00:00, 25.54it/s]\n",
      "Epoch 12/40: 100%|████████████████████████████████████████| 229/229 [00:08<00:00, 26.56it/s]\n",
      "Epoch 13/40: 100%|████████████████████████████████████████| 229/229 [00:08<00:00, 25.61it/s]\n",
      "Epoch 14/40: 100%|████████████████████████████████████████| 229/229 [00:08<00:00, 26.04it/s]\n",
      "Epoch 15/40: 100%|████████████████████████████████████████| 229/229 [00:09<00:00, 25.00it/s]\n",
      "Epoch 16/40: 100%|████████████████████████████████████████| 229/229 [00:08<00:00, 25.84it/s]\n",
      "Epoch 17/40: 100%|████████████████████████████████████████| 229/229 [00:08<00:00, 26.85it/s]\n",
      "Epoch 18/40: 100%|████████████████████████████████████████| 229/229 [00:08<00:00, 26.74it/s]\n",
      "Epoch 19/40: 100%|████████████████████████████████████████| 229/229 [00:09<00:00, 25.36it/s]\n",
      "Epoch 20/40: 100%|████████████████████████████████████████| 229/229 [00:09<00:00, 25.39it/s]\n",
      "Epoch 21/40: 100%|████████████████████████████████████████| 229/229 [00:15<00:00, 14.80it/s]\n",
      "Epoch 22/40: 100%|████████████████████████████████████████| 229/229 [00:24<00:00,  9.39it/s]\n",
      "Epoch 23/40: 100%|████████████████████████████████████████| 229/229 [00:09<00:00, 24.27it/s]\n",
      "Epoch 24/40: 100%|████████████████████████████████████████| 229/229 [00:08<00:00, 26.06it/s]\n",
      "Epoch 25/40: 100%|████████████████████████████████████████| 229/229 [00:11<00:00, 19.98it/s]\n",
      "Epoch 26/40: 100%|████████████████████████████████████████| 229/229 [00:09<00:00, 23.67it/s]\n",
      "Epoch 27/40: 100%|████████████████████████████████████████| 229/229 [00:09<00:00, 23.78it/s]\n",
      "Epoch 28/40: 100%|████████████████████████████████████████| 229/229 [00:09<00:00, 24.90it/s]\n",
      "Epoch 29/40: 100%|████████████████████████████████████████| 229/229 [00:09<00:00, 23.84it/s]\n",
      "Epoch 30/40: 100%|████████████████████████████████████████| 229/229 [00:09<00:00, 24.88it/s]\n",
      "Epoch 31/40: 100%|████████████████████████████████████████| 229/229 [00:09<00:00, 24.60it/s]\n",
      "Epoch 32/40: 100%|████████████████████████████████████████| 229/229 [00:09<00:00, 25.37it/s]\n",
      "Epoch 33/40: 100%|████████████████████████████████████████| 229/229 [00:09<00:00, 24.58it/s]\n",
      "Epoch 34/40: 100%|████████████████████████████████████████| 229/229 [00:09<00:00, 23.83it/s]\n",
      "Epoch 35/40: 100%|████████████████████████████████████████| 229/229 [00:09<00:00, 24.32it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 338.00 MiB. GPU 0 has a total capacity of 23.58 GiB of which 318.62 MiB is free. Process 1753384 has 2.60 GiB memory in use. Process 86073 has 5.46 GiB memory in use. Process 158408 has 2.46 GiB memory in use. Process 223655 has 5.55 GiB memory in use. Including non-PyTorch memory, this process has 6.46 GiB memory in use. Process 216647 has 360.00 MiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 365.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m discriminator \u001b[38;5;241m=\u001b[39m Discriminator()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      9\u001b[0m discriminator\u001b[38;5;241m.\u001b[39mapply(weights_init)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mtrain_dcgan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscriminator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_g\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr_g\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr_d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrun2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 94\u001b[0m, in \u001b[0;36mtrain_dcgan\u001b[0;34m(generator, discriminator, dataloader, latent_dim, epochs, device, lr_g, lr_d, beta1, step_size, gamma, project, name)\u001b[0m\n\u001b[1;32m     91\u001b[0m avg_d_loss \u001b[38;5;241m=\u001b[39m d_loss_total \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# Compute FID score\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m fid_score \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_fid_score_gan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Log metrics\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# wandb.log({\"Generator Loss\": avg_g_loss, \"Discriminator Loss\": avg_d_loss, \"FID Score\": fid_score})\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Log and save generated images as grids\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "Cell \u001b[0;32mIn[8], line 25\u001b[0m, in \u001b[0;36mcompute_fid_score_gan\u001b[0;34m(generator, data_loader, device, latent_dim, max_samples)\u001b[0m\n\u001b[1;32m     22\u001b[0m real_images \u001b[38;5;241m=\u001b[39m (real_images \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m255\u001b[39m)\u001b[38;5;241m.\u001b[39mbyte()\n\u001b[1;32m     23\u001b[0m fake_images \u001b[38;5;241m=\u001b[39m (fake_images \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m255\u001b[39m)\u001b[38;5;241m.\u001b[39mbyte()\n\u001b[0;32m---> 25\u001b[0m \u001b[43mfid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m fid\u001b[38;5;241m.\u001b[39mupdate(fake_images, real\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     28\u001b[0m total_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_size\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torchmetrics/metric.py:560\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected all tensors to be on\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n\u001b[1;32m    553\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    554\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered different devices in metric calculation (see stacktrace for details).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    555\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m This could be due to the metric class not being on the same device as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    558\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m device corresponds to the device of the input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    559\u001b[0m             ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m--> 560\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_on_cpu:\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_move_list_states_to_cpu()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torchmetrics/metric.py:550\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_grad):\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 550\u001b[0m         \u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    552\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected all tensors to be on\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torchmetrics/image/fid.py:369\u001b[0m, in \u001b[0;36mFrechetInceptionDistance.update\u001b[0;34m(self, imgs, real)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Update the state with extracted features.\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \n\u001b[1;32m    362\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    366\u001b[0m \n\u001b[1;32m    367\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    368\u001b[0m imgs \u001b[38;5;241m=\u001b[39m (imgs \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m255\u001b[39m)\u001b[38;5;241m.\u001b[39mbyte() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mused_custom_model) \u001b[38;5;28;01melse\u001b[39;00m imgs\n\u001b[0;32m--> 369\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minception\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_dtype \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    371\u001b[0m features \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mdouble()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torchmetrics/image/fid.py:156\u001b[0m, in \u001b[0;36mNoTrainInceptionV3.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    155\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass of neural network with reshaping of output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 156\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_torch_fidelity_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torchmetrics/image/fid.py:93\u001b[0m, in \u001b[0;36mNoTrainInceptionV3._torch_fidelity_forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     91\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mConv2d_1a_3x3(x)\n\u001b[1;32m     92\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mConv2d_2a_3x3(x)\n\u001b[0;32m---> 93\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConv2d_2b_3x3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMaxPool_1(x)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m64\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m remaining_features:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch_fidelity/feature_extractor_inceptionv3.py:209\u001b[0m, in \u001b[0;36mBasicConv2d.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    208\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(x)\n\u001b[0;32m--> 209\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mrelu(x, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    186\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/functional.py:2812\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2809\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2810\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2812\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2813\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2814\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2815\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2816\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2817\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2818\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2819\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2820\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2821\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2822\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 338.00 MiB. GPU 0 has a total capacity of 23.58 GiB of which 318.62 MiB is free. Process 1753384 has 2.60 GiB memory in use. Process 86073 has 5.46 GiB memory in use. Process 158408 has 2.46 GiB memory in use. Process 223655 has 5.55 GiB memory in use. Including non-PyTorch memory, this process has 6.46 GiB memory in use. Process 216647 has 360.00 MiB memory in use. Of the allocated memory 5.79 GiB is allocated by PyTorch, and 365.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "latent_dim = 128\n",
    "epochs = 40\n",
    "lr_g=0.0002\n",
    "lr_d=0.0004\n",
    "generator = Generator(latent_dim=latent_dim).to(device)\n",
    "generator.apply(weights_init)\n",
    "discriminator = Discriminator().to(device)\n",
    "discriminator.apply(weights_init)\n",
    "train_dcgan(generator, discriminator, train_loader, latent_dim, epochs, device, lr_g=lr_g, lr_d=lr_d, name='run2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe10e6ee-8d56-41f4-b20a-7f1b6174edf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mahmadjaved97\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/user/javeda1/MA-INF-4308-Lab-Vision-Systems/Assignment-6/wandb/run-20250119_213349-s2zjwjvo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ahmadjaved97/DCGAN-AFHQ2/runs/s2zjwjvo' target=\"_blank\">run3</a></strong> to <a href='https://wandb.ai/ahmadjaved97/DCGAN-AFHQ2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ahmadjaved97/DCGAN-AFHQ2' target=\"_blank\">https://wandb.ai/ahmadjaved97/DCGAN-AFHQ2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ahmadjaved97/DCGAN-AFHQ2/runs/s2zjwjvo' target=\"_blank\">https://wandb.ai/ahmadjaved97/DCGAN-AFHQ2/runs/s2zjwjvo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/40: 100%|█████████████████████████████████████████| 229/229 [00:11<00:00, 19.69it/s]\n",
      "Epoch 2/40: 100%|█████████████████████████████████████████| 229/229 [00:11<00:00, 20.14it/s]\n",
      "Epoch 3/40: 100%|█████████████████████████████████████████| 229/229 [00:11<00:00, 19.71it/s]\n",
      "Epoch 4/40: 100%|█████████████████████████████████████████| 229/229 [00:11<00:00, 20.42it/s]\n",
      "Epoch 5/40: 100%|█████████████████████████████████████████| 229/229 [00:11<00:00, 20.00it/s]\n",
      "Epoch 6/40: 100%|█████████████████████████████████████████| 229/229 [00:11<00:00, 20.38it/s]\n",
      "Epoch 7/40: 100%|█████████████████████████████████████████| 229/229 [00:11<00:00, 20.28it/s]\n",
      "Epoch 8/40: 100%|█████████████████████████████████████████| 229/229 [00:10<00:00, 20.88it/s]\n",
      "Epoch 9/40: 100%|█████████████████████████████████████████| 229/229 [00:11<00:00, 19.69it/s]\n",
      "Epoch 10/40: 100%|████████████████████████████████████████| 229/229 [00:11<00:00, 19.57it/s]\n",
      "Epoch 11/40: 100%|████████████████████████████████████████| 229/229 [00:10<00:00, 20.93it/s]\n",
      "Epoch 12/40: 100%|████████████████████████████████████████| 229/229 [00:11<00:00, 20.42it/s]\n",
      "Epoch 13/40: 100%|████████████████████████████████████████| 229/229 [00:10<00:00, 20.95it/s]\n",
      "Epoch 14/40: 100%|████████████████████████████████████████| 229/229 [00:10<00:00, 21.36it/s]\n",
      "Epoch 15/40: 100%|████████████████████████████████████████| 229/229 [00:11<00:00, 20.58it/s]\n",
      "Epoch 16/40: 100%|████████████████████████████████████████| 229/229 [00:11<00:00, 20.45it/s]\n",
      "Epoch 17/40: 100%|████████████████████████████████████████| 229/229 [00:11<00:00, 20.26it/s]\n",
      "Epoch 18/40: 100%|████████████████████████████████████████| 229/229 [00:11<00:00, 20.59it/s]\n",
      "Epoch 19/40: 100%|████████████████████████████████████████| 229/229 [00:11<00:00, 20.62it/s]\n",
      "Epoch 20/40: 100%|████████████████████████████████████████| 229/229 [00:10<00:00, 21.17it/s]\n",
      "Epoch 21/40: 100%|████████████████████████████████████████| 229/229 [00:11<00:00, 20.56it/s]\n",
      "Epoch 22/40: 100%|████████████████████████████████████████| 229/229 [00:11<00:00, 20.59it/s]\n",
      "Epoch 23/40: 100%|████████████████████████████████████████| 229/229 [00:11<00:00, 19.45it/s]\n",
      "Epoch 24/40: 100%|████████████████████████████████████████| 229/229 [00:11<00:00, 20.12it/s]\n",
      "Epoch 25/40: 100%|████████████████████████████████████████| 229/229 [00:11<00:00, 20.26it/s]\n",
      "Epoch 26/40: 100%|████████████████████████████████████████| 229/229 [00:11<00:00, 20.80it/s]\n",
      "Epoch 27/40: 100%|████████████████████████████████████████| 229/229 [00:10<00:00, 20.84it/s]\n",
      "Epoch 28/40: 100%|████████████████████████████████████████| 229/229 [00:11<00:00, 20.71it/s]\n",
      "Epoch 29/40: 100%|████████████████████████████████████████| 229/229 [00:11<00:00, 20.48it/s]\n",
      "Epoch 30/40: 100%|████████████████████████████████████████| 229/229 [00:11<00:00, 20.32it/s]\n",
      "Epoch 31/40: 100%|████████████████████████████████████████| 229/229 [00:11<00:00, 20.01it/s]\n",
      "Epoch 32/40: 100%|████████████████████████████████████████| 229/229 [00:11<00:00, 20.22it/s]\n",
      "Epoch 33/40: 100%|████████████████████████████████████████| 229/229 [00:11<00:00, 19.74it/s]\n",
      "Epoch 34/40: 100%|████████████████████████████████████████| 229/229 [00:11<00:00, 20.07it/s]\n",
      "Epoch 35/40: 100%|████████████████████████████████████████| 229/229 [00:11<00:00, 19.51it/s]\n",
      "Epoch 36/40: 100%|████████████████████████████████████████| 229/229 [00:11<00:00, 19.83it/s]\n",
      "Epoch 37/40: 100%|████████████████████████████████████████| 229/229 [00:10<00:00, 21.24it/s]\n",
      "Epoch 38/40: 100%|████████████████████████████████████████| 229/229 [00:11<00:00, 20.55it/s]\n",
      "Epoch 39/40: 100%|████████████████████████████████████████| 229/229 [00:10<00:00, 20.84it/s]\n",
      "Epoch 40/40: 100%|████████████████████████████████████████| 229/229 [00:11<00:00, 19.66it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Discriminator Loss</td><td>█▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>FID Score</td><td>▃▄▄▅▅▄▄▃▄▄▃▃▃▃▂▁▃▁▃▁▁▃▁▃▃▃▅▃▄▄▅▄▅▅▂█▄▂▆▅</td></tr><tr><td>Generator Loss</td><td>▁▁▁▁▁▁▂▂▃▃▂▂▃▄▄▄▄▄▄▄▃▄▅▅▆▆██▇█▆▆▆▆▇██▇▇▇</td></tr><tr><td>Learning Rate Discriminator</td><td>█████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Learning Rate Generator</td><td>█████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Discriminator Loss</td><td>0.13249</td></tr><tr><td>FID Score</td><td>273.90256</td></tr><tr><td>Generator Loss</td><td>4.19751</td></tr><tr><td>Learning Rate Discriminator</td><td>3e-05</td></tr><tr><td>Learning Rate Generator</td><td>1e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run3</strong> at: <a href='https://wandb.ai/ahmadjaved97/DCGAN-AFHQ2/runs/s2zjwjvo' target=\"_blank\">https://wandb.ai/ahmadjaved97/DCGAN-AFHQ2/runs/s2zjwjvo</a><br> View project at: <a href='https://wandb.ai/ahmadjaved97/DCGAN-AFHQ2' target=\"_blank\">https://wandb.ai/ahmadjaved97/DCGAN-AFHQ2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 80 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250119_213349-s2zjwjvo/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model\n",
    "latent_dim = 256\n",
    "epochs = 40\n",
    "lr_g=0.0002\n",
    "lr_d=0.0004\n",
    "generator = Generator(latent_dim=latent_dim).to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "train_dcgan(generator, discriminator, train_loader, latent_dim, epochs, device, lr_g=lr_g, lr_d=lr_d, name='run3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb28eabb-0622-41e6-9b1d-ef54db066fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/user/javeda1/MA-INF-4308-Lab-Vision-Systems/Assignment-6/wandb/run-20250120_021303-3r1ju485</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ahmadjaved97/DCGAN-AFHQ2/runs/3r1ju485' target=\"_blank\">run6</a></strong> to <a href='https://wandb.ai/ahmadjaved97/DCGAN-AFHQ2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ahmadjaved97/DCGAN-AFHQ2' target=\"_blank\">https://wandb.ai/ahmadjaved97/DCGAN-AFHQ2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ahmadjaved97/DCGAN-AFHQ2/runs/3r1ju485' target=\"_blank\">https://wandb.ai/ahmadjaved97/DCGAN-AFHQ2/runs/3r1ju485</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|█████████████████████████████████████████| 229/229 [01:17<00:00,  2.97it/s]\n",
      "Epoch 2/50: 100%|█████████████████████████████████████████| 229/229 [00:09<00:00, 25.03it/s]\n",
      "Epoch 3/50: 100%|█████████████████████████████████████████| 229/229 [00:08<00:00, 25.49it/s]\n",
      "Epoch 4/50: 100%|█████████████████████████████████████████| 229/229 [00:09<00:00, 25.37it/s]\n",
      "Epoch 5/50: 100%|█████████████████████████████████████████| 229/229 [00:09<00:00, 24.90it/s]\n",
      "Epoch 6/50: 100%|█████████████████████████████████████████| 229/229 [00:08<00:00, 25.59it/s]\n",
      "Epoch 7/50: 100%|█████████████████████████████████████████| 229/229 [00:09<00:00, 24.07it/s]\n",
      "Epoch 8/50: 100%|█████████████████████████████████████████| 229/229 [00:09<00:00, 25.17it/s]\n",
      "Epoch 9/50: 100%|█████████████████████████████████████████| 229/229 [00:08<00:00, 26.73it/s]\n",
      "Epoch 10/50: 100%|████████████████████████████████████████| 229/229 [00:08<00:00, 25.72it/s]\n",
      "Epoch 11/50: 100%|████████████████████████████████████████| 229/229 [00:08<00:00, 26.58it/s]\n",
      "Epoch 12/50: 100%|████████████████████████████████████████| 229/229 [00:09<00:00, 25.23it/s]\n",
      "Epoch 13/50: 100%|████████████████████████████████████████| 229/229 [00:09<00:00, 25.35it/s]\n",
      "Epoch 14/50: 100%|████████████████████████████████████████| 229/229 [00:08<00:00, 26.42it/s]\n",
      "Epoch 15/50: 100%|████████████████████████████████████████| 229/229 [00:08<00:00, 26.16it/s]\n",
      "Epoch 16/50: 100%|████████████████████████████████████████| 229/229 [00:09<00:00, 25.22it/s]\n",
      "Epoch 17/50: 100%|████████████████████████████████████████| 229/229 [00:08<00:00, 26.46it/s]\n",
      "Epoch 18/50: 100%|████████████████████████████████████████| 229/229 [00:08<00:00, 25.59it/s]\n",
      "Epoch 19/50: 100%|████████████████████████████████████████| 229/229 [00:08<00:00, 26.62it/s]\n",
      "Epoch 20/50: 100%|████████████████████████████████████████| 229/229 [00:09<00:00, 25.35it/s]\n",
      "Epoch 21/50: 100%|████████████████████████████████████████| 229/229 [00:08<00:00, 25.60it/s]\n",
      "Epoch 22/50: 100%|████████████████████████████████████████| 229/229 [00:08<00:00, 26.33it/s]\n",
      "Epoch 23/50: 100%|████████████████████████████████████████| 229/229 [00:09<00:00, 25.26it/s]\n",
      "Epoch 24/50: 100%|████████████████████████████████████████| 229/229 [00:08<00:00, 25.69it/s]\n",
      "Epoch 25/50: 100%|████████████████████████████████████████| 229/229 [00:09<00:00, 24.48it/s]\n",
      "Epoch 26/50: 100%|████████████████████████████████████████| 229/229 [00:08<00:00, 25.45it/s]\n",
      "Epoch 27/50: 100%|████████████████████████████████████████| 229/229 [00:08<00:00, 25.52it/s]\n",
      "Epoch 28/50: 100%|████████████████████████████████████████| 229/229 [00:09<00:00, 24.69it/s]\n",
      "Epoch 29/50: 100%|████████████████████████████████████████| 229/229 [00:08<00:00, 26.47it/s]\n",
      "Epoch 30/50: 100%|████████████████████████████████████████| 229/229 [00:08<00:00, 26.66it/s]\n",
      "Epoch 31/50: 100%|████████████████████████████████████████| 229/229 [00:08<00:00, 26.05it/s]\n",
      "Epoch 32/50: 100%|████████████████████████████████████████| 229/229 [00:08<00:00, 25.57it/s]\n",
      "Epoch 33/50: 100%|████████████████████████████████████████| 229/229 [00:08<00:00, 26.31it/s]\n",
      "Epoch 34/50: 100%|████████████████████████████████████████| 229/229 [00:09<00:00, 24.73it/s]\n",
      "Epoch 35/50: 100%|████████████████████████████████████████| 229/229 [00:09<00:00, 25.23it/s]\n",
      "Epoch 36/50: 100%|████████████████████████████████████████| 229/229 [00:08<00:00, 25.52it/s]\n",
      "Epoch 37/50: 100%|████████████████████████████████████████| 229/229 [00:09<00:00, 25.15it/s]\n",
      "Epoch 38/50: 100%|████████████████████████████████████████| 229/229 [00:08<00:00, 25.64it/s]\n",
      "Epoch 39/50: 100%|████████████████████████████████████████| 229/229 [00:08<00:00, 25.60it/s]\n",
      "Epoch 40/50: 100%|████████████████████████████████████████| 229/229 [00:09<00:00, 24.97it/s]\n",
      "Epoch 41/50: 100%|████████████████████████████████████████| 229/229 [00:09<00:00, 25.38it/s]\n",
      "Epoch 42/50: 100%|████████████████████████████████████████| 229/229 [00:09<00:00, 25.07it/s]\n",
      "Epoch 43/50: 100%|████████████████████████████████████████| 229/229 [00:09<00:00, 25.00it/s]\n",
      "Epoch 44/50: 100%|████████████████████████████████████████| 229/229 [00:09<00:00, 25.12it/s]\n",
      "Epoch 45/50: 100%|████████████████████████████████████████| 229/229 [00:08<00:00, 25.54it/s]\n",
      "Epoch 46/50: 100%|████████████████████████████████████████| 229/229 [00:08<00:00, 25.61it/s]\n",
      "Epoch 47/50: 100%|████████████████████████████████████████| 229/229 [00:08<00:00, 25.55it/s]\n",
      "Epoch 48/50: 100%|████████████████████████████████████████| 229/229 [00:08<00:00, 26.16it/s]\n",
      "Epoch 49/50: 100%|████████████████████████████████████████| 229/229 [00:08<00:00, 25.61it/s]\n",
      "Epoch 50/50: 100%|████████████████████████████████████████| 229/229 [00:08<00:00, 25.60it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Discriminator Loss</td><td>█▅▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>FID Score</td><td>▆▇█▇▆▇▇▇▇▇▆▆▇▆▆▄▄▄▃▃▃▅▄▄▁▃▄▅▄▃▅▃▂▁▄▂▃▃▃▄</td></tr><tr><td>Generator Loss</td><td>▃▁▂▄▆▅▅▅▅▄▆▆▇▆▇▅▅▆▆▆▇▇▇▇▇▇▇▇████▇▇▇▇▇███</td></tr><tr><td>Learning Rate Discriminator</td><td>████████▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Learning Rate Generator</td><td>████████▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Discriminator Loss</td><td>0.1338</td></tr><tr><td>FID Score</td><td>197.31503</td></tr><tr><td>Generator Loss</td><td>3.77325</td></tr><tr><td>Learning Rate Discriminator</td><td>1e-05</td></tr><tr><td>Learning Rate Generator</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run6</strong> at: <a href='https://wandb.ai/ahmadjaved97/DCGAN-AFHQ2/runs/3r1ju485' target=\"_blank\">https://wandb.ai/ahmadjaved97/DCGAN-AFHQ2/runs/3r1ju485</a><br> View project at: <a href='https://wandb.ai/ahmadjaved97/DCGAN-AFHQ2' target=\"_blank\">https://wandb.ai/ahmadjaved97/DCGAN-AFHQ2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 100 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250120_021303-3r1ju485/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model\n",
    "latent_dim = 100\n",
    "epochs = 50\n",
    "lr_g=0.0001\n",
    "lr_d=0.0003\n",
    "generator = Generator(latent_dim=latent_dim).to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "train_dcgan(generator, discriminator, train_loader, latent_dim, epochs, device, lr_g=lr_g, lr_d=lr_d, name='run6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f791ed5-7971-4c33-b9b3-d48c5787862a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
